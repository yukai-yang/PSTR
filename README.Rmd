---
output:
  md_document:
    variant: markdown_github
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, echo = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "README-"
)
```

# PSTR version 1.2.1 (Orange Panel)

[![CRAN_Status_Badge](http://www.r-pkg.org/badges/version/PSTR?color=green)](https://cran.r-project.org/package=PSTR) 
![](http://cranlogs.r-pkg.org/badges/grand-total/PSTR?color=green) 
![](http://cranlogs.r-pkg.org/badges/PSTR?color=green) 
![](http://cranlogs.r-pkg.org/badges/last-week/PSTR?color=green) 

The PSTR package implements the Panel Smooth Transition Regression (PSTR) modelling. You can also find the package on CRAN, see

[PSTR@CRAN](https://cran.r-project.org/web/packages/PSTR)

The modelling procedure consists of three stages: Specification, Estimation and Evaluation. The package offers tools helping the users to conduct model specification tests, to do PSTR model estimation, and to do model evaluation.

The cluster-dependency and heteroskedasticity-consistent tests are implemented in the package.

The wild bootstrap and cluster wild bootstrap tests are also implemented.

Parallel computation (as an option) is implemented in some functions, especially the bootstrap tests. Therefore, the package suits tasks running many cores on super-computation servers.

## How to install

You can either install the stable version from CRAN
```{r install1, eval=F}
install.packages("PSTR")
```
or install the development version from GitHub
```{r install2, eval=F}
devtools::install_github("yukai-yang/PSTR")
```
provided that the package "devtools" has been installed beforehand.

## Example

After installing the package, you need to load (attach better say) it by running the code
```{r attach}
library(PSTR)
```

You can first check the information and the current version number by running
```{r version}
version()
```

Then you can take a look at all the available functions and data in the package
```{r contents}
ls( grep("PSTR", search()) ) 
```

In the package, a data set called "Hansen99" is offered to give prompt example. For details of the data set, you can run
```{r data, eval=F}
?Hansen99 
```

You can create a new object of the class PSTR by doing
```{r new}
pstr = NewPSTR(Hansen99, dep='inva', indep=4:20, indep_k=c('vala','debta','cfa','sales'),
               tvars=c('vala'), im=1, iT=14)
print(pstr)
```
It says that the data set "Hansen99" is used, the dependent variable is "inva", the variables in the data from column 4 to 20 are the explanatory variables in the linear part (though you can write down the names of them), the explanatory variables in the nonlinear part are the four ones in "indep_k", and the potential transition variable is "vala" (Tobin's Q).

Now you can see that the "NewPSTR" is basically defining the settings of the model.

Note that you can print the object of the class PSTR. By default, it gives you a summary of the PSTR model. They are mainly about which one is the dependent variable, which ones are explanatory variables and etc..

The following code does linearity tests
```{r lintest}
pstr = LinTest(use=pstr) 
print(pstr, "tests")
```
You can see that the function "LinTest" takes the PSTR object "pstr" and overwrites it when return. This is the way I recommend as the functions handling the PSTR object in the package update the object by adding new atrributes or members. However, the same function will change the values of the attributes it adds. You can of course create new PSTR objects to take the return values in order to save the results from different settings of the model.

You can do the wild bootstrap and wild cluster bootstrap by running the following code. (Warning! Don't run it except that you have at least 50 cores!)
```{r lintest3, eval=F}
iB = 5000 # the number of repetitions in the bootstrap
library(snowfall)
pstr = WCB_LinTest(use=pstr,iB=iB,parallel=T,cpus=50)
```
It takes a long long time to run the bootstrap. This function is developed for those who work on some super-computation server with many cores and a large memory. Note that you will have to attach the "snowfall" package manually.

But of course, you can try the function on your personal computer by reducing the number of repetitions and the cores.
```{r lintest4, eval=F}
pstr = WCB_LinTest(use=pstr,iB=4,parallel=T,cpus=2)
```

When you determine which transition variable to use for the estimation, in this case "inva", you can estimate the PSTR model
```{r estimate, eval=F}
pstr = EstPSTR(use=pstr,im=1,iq=1,useDelta=T,par=c(1.6,.5), vLower=4, vUpper=4)
print(pstr,"estimates")
```
By default, the "optim" method "L-BFGS-B" is used, but you can change the method for estimation by doing
```{r estimate1}
pstr = EstPSTR(use=pstr,im=1,iq=1,useDelta=T,par=c(1.6,.5), method="CG")
print(pstr,"estimates")
```

The argument "useDelta" determines the type of the initial value for the smoothness parameter. By default "useDelta = F" means that the first initial value in "par" is the "gamma" instead of "delta". Here we use the settings "useDelta = T" and "par = c(1.6, .5)" means that the first value of "par" is the "delta" and its value is 1.6. Note that "delta" and "gamma" has the relationship "gamma = exp(delta)". Thus, the following two sentences are equivalent
```{r estimate2, eval=F}
pstr = EstPSTR(use=pstr,im=1,iq=1,useDelta=T,par=c(1.6,.5), method="CG")
pstr = EstPSTR(use=pstr,im=1,iq=1,par=c(exp(1.6),.5), method="CG")
```
For details, read the vignette.

Now you can plot the estimated transition function by running
```{r plot}
plot_transition(pstr, log_scale=TRUE, color = "blue", size = 2,
    x="Tobin's Q in log scale", title="The Estimated Transition Function",
    caption="If you wanna write something in the caption, do it here.")
```

Note that the estimation of a linear panel regression model is also implemented. The user can do it by simply running
```{r estimate3}
pstr0 = EstPSTR(use=pstr)
print(pstr0,"estimates")
```


The evaluation tests can be done based on the estimated model
```{r evaluation, eval=F}
## evaluatio tests
pstr1 = EvalTest(use=pstr,vq=pstr$mQ[,1])
```  
Note that in the "EvalTest", only one transition variable is taken each time for the no remaining nonlinearity test. This is different from the "LinTest" function which can take several transition variables. This is the reason why I save the results into new PSTR objects "pstr1" instead of overwriting. By doing so, I can save more test results from different transition variables in new objects. 

The user can also do the wild bootstrap and wild cluster bootstrap in the following way, provided that he or she has the super-computation resources.
```{r evaluation1, eval=F}
iB = 5000
cpus = 50

## wild bootstrap time-varyint evaluation test 
pstr = WCB_TVTest(use=pstr,iB=iB,parallel=T,cpus=cpus)

## wild bootstrap heterogeneity evaluation test
pstr1 = WCB_HETest(use=pstr1,vq=pstr$mQ[,1],iB=iB,parallel=T,cpus=cpus)
```

Note that the evaluation functions do not accept the returned object "pstr0" from a linear panel regression model, as the evaluation tests are designed for the estimated PSTR model but not a linear one.
